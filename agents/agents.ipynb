{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403516e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages (from arxiv) (2.32.5)\n",
      "Requirement already satisfied: sgmllib3k in /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd66b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exe: /Users/varunsardana/Desktop/Langchain-Project/Langchain/bin/python\n",
      "langchain_ollama file: /Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_ollama/__init__.py\n",
      "langchain-ollama version: 0.3.7\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib, os\n",
    "print(\"Python exe:\", sys.executable)\n",
    "\n",
    "try:\n",
    "    import langchain_ollama\n",
    "    print(\"langchain_ollama file:\", langchain_ollama.__file__)\n",
    "    try:\n",
    "        from importlib.metadata import version\n",
    "    except Exception:\n",
    "        from importlib_metadata import version  # py<3.8\n",
    "    print(\"langchain-ollama version:\", version(\"langchain-ollama\"))\n",
    "except Exception as e:\n",
    "    print(\"langchain_ollama not importable:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d86b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Mac) LangChainNotebook/1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1653114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust import that works across versions\n",
    "try:\n",
    "    from langchain_ollama.embeddings import OllamaEmbeddings   # ✅ 0.3.x path\n",
    "except ImportError:\n",
    "    from langchain_community.embeddings import OllamaEmbeddings # legacy fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3475815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, list)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vec = emb.embed_query(\"hello world\")   # should return a vector (list of floats)\n",
    "len(vec), type(vec[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719cd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bb4ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper= WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki= WikipediaQueryRun(api_wrapper=api_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3385019b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95c7b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Wikipedia\n",
      "Summary: Wikipedia is a free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and the wiki software MediaWiki. \n"
     ]
    }
   ],
   "source": [
    "result= wiki.invoke({\"query\": \"Who founded Wikipedia?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bded0098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11878aa70>, search_kwargs={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter   \n",
    "\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Artificial_intelligence\")\n",
    "docs = loader.load()\n",
    "documents= RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectordb= FAISS.from_documents(documents, OllamaEmbeddings(model=\"nomic-embed-text\"))\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a156de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool= create_retriever_tool(retriever, \"artificial_intelligence search\", \" Search for when you need to find information on artificial intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07024179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artificial_intelligence search'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8141150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arxiv Tool\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper= ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bdeefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, arxiv, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a64aad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='artificial_intelligence search', description=' Search for when you need to find information on artificial intelligence', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x10fe8c5e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11878aa70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x10fe8c550>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11878aa70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84c5ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm= ChatOllama(model= \"gemma3:1b\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "044b86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302fe08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "tools = [wiki, arxiv, retriever_tool]\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0a8a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\narxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\\nartificial_intelligence search(query: \\'str\\', *, retriever: \\'BaseRetriever\\' = VectorStoreRetriever(tags=[\\'FAISS\\', \\'OllamaEmbeddings\\'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11878aa70>, search_kwargs={}), document_prompt: \\'BasePromptTemplate\\' = PromptTemplate(input_variables=[\\'page_content\\'], input_types={}, partial_variables={}, template=\\'{page_content}\\'), document_separator: \\'str\\' = \\'\\\\n\\\\n\\', callbacks: \\'Callbacks\\' = None, response_format: \"Literal[\\'content\\', \\'content_and_artifact\\']\" = \\'content\\') -> \\'Union[str, tuple[str, list[Document]]]\\' -  Search for when you need to find information on artificial intelligence', 'tool_names': 'wikipedia, arxiv, artificial_intelligence search'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatOllama(model='gemma3:1b', temperature=0.0), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/varunsardana/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='artificial_intelligence search', description=' Search for when you need to find information on artificial intelligence', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x10fe8c5e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11878aa70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x10fe8c550>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11878aa70>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Executor\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools= tools, verbose= True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ede32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find information about Artificial Intelligence. I’ll start with a general search on Wikipedia.\n",
      "Action: wikipedia\n",
      "Action Input: “Artificial intelligence”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasonin\u001b[0m\u001b[32;1m\u001b[1;3mI need to understand the basics of AI. Let’s start with a general overview from Wikipedia.\n",
      "Action: wikipedia\n",
      "Action Input: “Artificial intelligence”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasonin\u001b[0m\u001b[32;1m\u001b[1;3mI understand the basics of AI. Let’s delve deeper.\n",
      "Action: wikipedia\n",
      "Action Input: “Artificial intelligence”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasonin\u001b[0m\u001b[32;1m\u001b[1;3mI need to refine my understanding of AI. Can you provide me with more specific details about its history, different types, and prominent applications?\n",
      "Final Answer: The page provides a basic overview of AI, including its definition and key aspects like learning and reasoning. It also mentions different types like machine learning, deep learning, and natural language processing.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Artificial Intelligence',\n",
       " 'output': 'The page provides a basic overview of AI, including its definition and key aspects like learning and reasoning. It also mentions different types like machine learning, deep learning, and natural language processing.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Tell me about Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72208f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to answer about Machine Learning and its applications. Let’s start with a general overview.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mI need to provide a general overview of Machine Learning. It’s a broad field with many sub-disciplines. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mI need to provide a general overview of Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mI need to provide a general overview of Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mI need to provide a general overview of Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mI need to provide a general overview of Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mI need to provide a general overview of Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: Tell me about Machine Learning and its applications\n",
      "Thought: I need to answer about Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: Tell me about Machine Learning and its applications\n",
      "Thought: I need to answer about Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What are the main types of Machine Learning?\n",
      "Thought: I need to identify the main types of Machine Learning. Let’s start with a broad categorization.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What are the main types of Machine Learning?\n",
      "Thought: I need to identify the main types of Machine Learning. Let’s start with a broad categorization.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What are the main types of Machine Learning?\n",
      "Thought: I need to list the main types of Machine Learning. Let’s start with a broad categorization.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What are the main types of Machine Learning?\n",
      "Thought: I need to list the main types of Machine Learning. Let’s start with a broad categorization.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: Tell me about Machine Learning and its applications\n",
      "Thought: I need to provide a general overview of Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: Tell me about Machine Learning and its applications\n",
      "Thought: I need to answer about Machine Learning and its applications. Let’s start with a basic definition and some key aspects.\n",
      "Action: wikipedia\n",
      "Action Input: “Machine learning”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Machine Learning and its applications',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Tell me about Machine Learning and its applications\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2e7e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to understand what Artificial Intelligence encompasses. I’ll start with a general search to get a broad overview.\n",
      "Action: wikipedia\n",
      "Action Input: “Artificial intelligence”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasonin\u001b[0m\u001b[32;1m\u001b[1;3mI need to understand the different types of AI and how they work. Let’s start with a general overview.\n",
      "Action: wikipedia\n",
      "Action Input: “Artificial intelligence”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasonin\u001b[0m\u001b[32;1m\u001b[1;3mI understand the basics of AI. I need to delve deeper into the specifics.\n",
      "Action: wikipedia\n",
      "Action Input: “Artificial intelligence”\u001b[0m\u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasonin\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Parsing LLM output produced both a final answer and a parse-able action:: I think I have a good grasp of what AI is. Can you give me some examples of different types of AI?\nFinal Answer:\nAction: wikipedia\nAction Input: “Types of Artificial Intelligence”\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain/agents/agent.py:1352\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1352\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain/agents/agent.py:455\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:3473\u001b[0m, in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRunnableParallel\u001b[39;00m(RunnableSerializable[Input, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]):\n\u001b[1;32m   3472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runnable that runs a mapping of Runnables in parallel.\u001b[39;00m\n\u001b[0;32m-> 3473\u001b[0m \n\u001b[1;32m   3474\u001b[0m \u001b[38;5;124;03m    Returns a mapping of their outputs.\u001b[39;00m\n\u001b[1;32m   3475\u001b[0m \n\u001b[1;32m   3476\u001b[0m \u001b[38;5;124;03m    RunnableParallel is one of the two main composition primitives for the LCEL,\u001b[39;00m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;124;03m    alongside RunnableSequence. It invokes Runnables concurrently, providing the same\u001b[39;00m\n\u001b[1;32m   3478\u001b[0m \u001b[38;5;124;03m    input to each.\u001b[39;00m\n\u001b[1;32m   3479\u001b[0m \n\u001b[1;32m   3480\u001b[0m \u001b[38;5;124;03m    A RunnableParallel can be instantiated directly or by using a dict literal within a\u001b[39;00m\n\u001b[1;32m   3481\u001b[0m \u001b[38;5;124;03m    sequence.\u001b[39;00m\n\u001b[1;32m   3482\u001b[0m \n\u001b[1;32m   3483\u001b[0m \u001b[38;5;124;03m    Here is a simple example that uses functions to illustrate the use of\u001b[39;00m\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;124;03m    RunnableParallel:\u001b[39;00m\n\u001b[1;32m   3485\u001b[0m \n\u001b[1;32m   3486\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m   3487\u001b[0m \n\u001b[1;32m   3488\u001b[0m \u001b[38;5;124;03m            from langchain_core.runnables import RunnableLambda\u001b[39;00m\n\u001b[1;32m   3489\u001b[0m \n\u001b[1;32m   3490\u001b[0m \u001b[38;5;124;03m            def add_one(x: int) -> int:\u001b[39;00m\n\u001b[1;32m   3491\u001b[0m \u001b[38;5;124;03m                return x + 1\u001b[39;00m\n\u001b[1;32m   3492\u001b[0m \n\u001b[1;32m   3493\u001b[0m \u001b[38;5;124;03m            def mul_two(x: int) -> int:\u001b[39;00m\n\u001b[1;32m   3494\u001b[0m \u001b[38;5;124;03m                return x * 2\u001b[39;00m\n\u001b[1;32m   3495\u001b[0m \n\u001b[1;32m   3496\u001b[0m \u001b[38;5;124;03m            def mul_three(x: int) -> int:\u001b[39;00m\n\u001b[1;32m   3497\u001b[0m \u001b[38;5;124;03m                return x * 3\u001b[39;00m\n\u001b[1;32m   3498\u001b[0m \n\u001b[1;32m   3499\u001b[0m \u001b[38;5;124;03m            runnable_1 = RunnableLambda(add_one)\u001b[39;00m\n\u001b[1;32m   3500\u001b[0m \u001b[38;5;124;03m            runnable_2 = RunnableLambda(mul_two)\u001b[39;00m\n\u001b[1;32m   3501\u001b[0m \u001b[38;5;124;03m            runnable_3 = RunnableLambda(mul_three)\u001b[39;00m\n\u001b[1;32m   3502\u001b[0m \n\u001b[1;32m   3503\u001b[0m \u001b[38;5;124;03m            sequence = runnable_1 | {  # this dict is coerced to a RunnableParallel\u001b[39;00m\n\u001b[1;32m   3504\u001b[0m \u001b[38;5;124;03m                \"mul_two\": runnable_2,\u001b[39;00m\n\u001b[1;32m   3505\u001b[0m \u001b[38;5;124;03m                \"mul_three\": runnable_3,\u001b[39;00m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;124;03m            }\u001b[39;00m\n\u001b[1;32m   3507\u001b[0m \u001b[38;5;124;03m            # Or equivalently:\u001b[39;00m\n\u001b[1;32m   3508\u001b[0m \u001b[38;5;124;03m            # sequence = runnable_1 | RunnableParallel(\u001b[39;00m\n\u001b[1;32m   3509\u001b[0m \u001b[38;5;124;03m            #     {\"mul_two\": runnable_2, \"mul_three\": runnable_3}\u001b[39;00m\n\u001b[1;32m   3510\u001b[0m \u001b[38;5;124;03m            # )\u001b[39;00m\n\u001b[1;32m   3511\u001b[0m \u001b[38;5;124;03m            # Also equivalently:\u001b[39;00m\n\u001b[1;32m   3512\u001b[0m \u001b[38;5;124;03m            # sequence = runnable_1 | RunnableParallel(\u001b[39;00m\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;124;03m            #     mul_two=runnable_2,\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;124;03m            #     mul_three=runnable_3,\u001b[39;00m\n\u001b[1;32m   3515\u001b[0m \u001b[38;5;124;03m            # )\u001b[39;00m\n\u001b[1;32m   3516\u001b[0m \n\u001b[1;32m   3517\u001b[0m \u001b[38;5;124;03m            sequence.invoke(1)\u001b[39;00m\n\u001b[1;32m   3518\u001b[0m \u001b[38;5;124;03m            await sequence.ainvoke(1)\u001b[39;00m\n\u001b[1;32m   3519\u001b[0m \n\u001b[1;32m   3520\u001b[0m \u001b[38;5;124;03m            sequence.batch([1, 2, 3])\u001b[39;00m\n\u001b[1;32m   3521\u001b[0m \u001b[38;5;124;03m            await sequence.abatch([1, 2, 3])\u001b[39;00m\n\u001b[1;32m   3522\u001b[0m \n\u001b[1;32m   3523\u001b[0m \u001b[38;5;124;03m    RunnableParallel makes it easy to run Runnables in parallel. In the below example,\u001b[39;00m\n\u001b[1;32m   3524\u001b[0m \u001b[38;5;124;03m    we simultaneously stream output from two different Runnables:\u001b[39;00m\n\u001b[1;32m   3525\u001b[0m \n\u001b[1;32m   3526\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m   3527\u001b[0m \n\u001b[1;32m   3528\u001b[0m \u001b[38;5;124;03m            from langchain_core.prompts import ChatPromptTemplate\u001b[39;00m\n\u001b[1;32m   3529\u001b[0m \u001b[38;5;124;03m            from langchain_core.runnables import RunnableParallel\u001b[39;00m\n\u001b[1;32m   3530\u001b[0m \u001b[38;5;124;03m            from langchain_openai import ChatOpenAI\u001b[39;00m\n\u001b[1;32m   3531\u001b[0m \n\u001b[1;32m   3532\u001b[0m \u001b[38;5;124;03m            model = ChatOpenAI()\u001b[39;00m\n\u001b[1;32m   3533\u001b[0m \u001b[38;5;124;03m            joke_chain = (\u001b[39;00m\n\u001b[1;32m   3534\u001b[0m \u001b[38;5;124;03m                ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\u001b[39;00m\n\u001b[1;32m   3535\u001b[0m \u001b[38;5;124;03m                | model\u001b[39;00m\n\u001b[1;32m   3536\u001b[0m \u001b[38;5;124;03m            )\u001b[39;00m\n\u001b[1;32m   3537\u001b[0m \u001b[38;5;124;03m            poem_chain = (\u001b[39;00m\n\u001b[1;32m   3538\u001b[0m \u001b[38;5;124;03m                ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\")\u001b[39;00m\n\u001b[1;32m   3539\u001b[0m \u001b[38;5;124;03m                | model\u001b[39;00m\n\u001b[1;32m   3540\u001b[0m \u001b[38;5;124;03m            )\u001b[39;00m\n\u001b[1;32m   3541\u001b[0m \n\u001b[1;32m   3542\u001b[0m \u001b[38;5;124;03m            runnable = RunnableParallel(joke=joke_chain, poem=poem_chain)\u001b[39;00m\n\u001b[1;32m   3543\u001b[0m \n\u001b[1;32m   3544\u001b[0m \u001b[38;5;124;03m            # Display stream\u001b[39;00m\n\u001b[1;32m   3545\u001b[0m \u001b[38;5;124;03m            output = {key: \"\" for key, _ in runnable.output_schema()}\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m \u001b[38;5;124;03m            for chunk in runnable.stream({\"topic\": \"bear\"}):\u001b[39;00m\n\u001b[1;32m   3547\u001b[0m \u001b[38;5;124;03m                for key in chunk:\u001b[39;00m\n\u001b[1;32m   3548\u001b[0m \u001b[38;5;124;03m                    output[key] = output[key] + chunk[key].content\u001b[39;00m\n\u001b[1;32m   3549\u001b[0m \u001b[38;5;124;03m                print(output)  # noqa: T201\u001b[39;00m\n\u001b[1;32m   3550\u001b[0m \n\u001b[1;32m   3551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3553\u001b[0m     steps__: Mapping[\u001b[38;5;28mstr\u001b[39m, Runnable[Input, Any]]\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:3459\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3455\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   3457\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   3458\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mastream\u001b[39m(\n\u001b[0;32m-> 3459\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3460\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   3461\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3462\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[1;32m   3464\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minput_aiter\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Input]:\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2233\u001b[0m, in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2233\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2234\u001b[0m         final_input \u001b[38;5;241m=\u001b[39m final_input \u001b[38;5;241m+\u001b[39m ichunk  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:3421\u001b[0m, in \u001b[0;36m_transform\u001b[0;34m(self, inputs, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3417\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m output\n\u001b[1;32m   3419\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   3420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m-> 3421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3422\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   3423\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3424\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3425\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m   3426\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   3427\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3428\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   3429\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   3430\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3431\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1460\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Input],  \u001b[38;5;66;03m# noqa: A002\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   1455\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Default implementation of atransform, which buffers input and calls astream.\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \n\u001b[1;32m   1458\u001b[0m \u001b[38;5;124;03m    Subclasses should override this method if they can start producing output while\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;124;03m    input is still being generated.\u001b[39;00m\n\u001b[0;32m-> 1460\u001b[0m \n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m        input: An async iterator of inputs to the Runnable.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m        config: The config to use for the Runnable. Defaults to None.\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m        kwargs: Additional keyword arguments to pass to the Runnable.\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m \n\u001b[1;32m   1466\u001b[0m \u001b[38;5;124;03m    Yields:\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;124;03m        The output of the Runnable.\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1469\u001b[0m     final: Input\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1024\u001b[0m, in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mastream\u001b[39m(\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,  \u001b[38;5;66;03m# noqa: A002\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   1022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Default implementation of astream, which calls ainvoke.\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m \n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03m    Subclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m        input: The input to the Runnable.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m        config: The config to use for the Runnable. Defaults to None.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m        kwargs: Additional keyword arguments to pass to the Runnable.\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \n\u001b[1;32m   1032\u001b[0m \u001b[38;5;124;03m    Yields:\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;03m        The output of the Runnable.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:197\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    208\u001b[0m     config,\n\u001b[1;32m    209\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1953\u001b[0m, in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/runnables/config.py:429\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:198\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 198\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    202\u001b[0m         config,\n\u001b[1;32m    203\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    208\u001b[0m     config,\n\u001b[1;32m    209\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:251\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03mThe return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    Structured output.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain/agents/output_parsers/react_single_input.py:60\u001b[0m, in \u001b[0;36mReActSingleInputOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     59\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINAL_ANSWER_AND_PARSABLE_ACTION_ERROR_MESSAGE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg)\n\u001b[1;32m     61\u001b[0m action \u001b[38;5;241m=\u001b[39m action_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Parsing LLM output produced both a final answer and a parse-able action:: I think I have a good grasp of what AI is. Can you give me some examples of different types of AI?\nFinal Answer:\nAction: wikipedia\nAction Input: “Types of Artificial Intelligence”\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat can Artificial Intelligence do?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain/chains/base.py:165\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    164\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 165\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    170\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    171\u001b[0m         inputs,\n\u001b[1;32m    172\u001b[0m         outputs,\n\u001b[1;32m    173\u001b[0m         return_only_outputs,\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain/agents/agent.py:1625\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1625\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1634\u001b[0m             next_step_output,\n\u001b[1;32m   1635\u001b[0m             intermediate_steps,\n\u001b[1;32m   1636\u001b[0m             run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1637\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain/agents/agent.py:1325\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1318\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1325\u001b[0m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1334\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Langchain-Project/Langchain/lib/python3.10/site-packages/langchain/agents/agent.py:1369\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m   1363\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m     )\n\u001b[0;32m-> 1369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1370\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Parsing LLM output produced both a final answer and a parse-able action:: I think I have a good grasp of what AI is. Can you give me some examples of different types of AI?\nFinal Answer:\nAction: wikipedia\nAction Input: “Types of Artificial Intelligence”\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What can Artificial Intelligence do?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
